# Отчет по учебному исследовательскому проекту - реимплеменация научной статьи "StyleGAN-NADA: CLIP-Guided Domain Adaptation of Image Generators"

## Постановка проблемы
>StyleGAN-NADA решает проблему адаптации генераторов изображений к новым доменам без необходимости аннотированных данных.
>StyleCLIP может редактировать изображение только в пределах домена генератора. StyleGAN-NADA  изменяет веса генератора и, следовательно, может выходить за пределы домена. Модель способна применять изменения, которые выходят за рамки всех подходов StyleCLIP.

## Ключевая идея
>Поскольку оптимизирован сам генератор (а не отдельные скрытые векторы), после обучения он может бесконечно производить генерацию изображений в целевом домене.
>Это обеспечивает гибкие zero-shot преобразования, не требуя разметки данных или обучения с нуля.

## Описание решения:
Регуляризация процесса дообучения делается с помощью ограничения количества весов, которые могут меняться во время каждой итерации.
Выбираем k-top релевантных слоев, изменения в которых были теснее всего связаны с выполяемым изменением target -> source.

**Алгоритм выбора слоев для разморозки**
1. Временно размораживаем все слои модели чтобы можно было работать с градиентами.
2. Выбираем слои, которые будем обучать. В нашем случае это convs (используется Style GAN 2 для PyTorch https://github.com/rosinality/stylegan2-pytorch).
3. Проводим итерацию по обучению с помощью global CLIP-loss. 
4. Для обучаемых слоев вычисляем градиент.
5. Выбираем top-k слоев с наибольшей нормой градиента.
6. Замораживаем в convs все слои, кроме выбранных top-k слоев
>select_layers_to_unfreeze # реализция алгоритма

**Как строить обучение**
1. Загружаем модедели и веса:
  - [Installed CLIP](https://github.com/openai/CLIP)
  - [Style GAN 2 (in Pytorch)](https://github.com/rosinality/stylegan2-pytorch)
  - [Weights for StyleGAN2-ffhq One-Shot Adaptation of GAN in Just One CLIP (pytorch)](https://huggingface.co/akhaliq/OneshotCLIP-stylegan2-ffhq/resolve/main/stylegan2-ffhq-config-f.pt)
2. Ищем top-k слоев в convs которые будут разморожены. Остальные слои в convs замораживаем.
3. Для обучения используем directional CLIP-loss.
4. Проводим заранее определенное количество итераций по выбранным промптам. Каждые M (например, 50) итераций выводим пару изображений (текущее и изначальное) для оценки качества сгенерированных изображений.

**Описание эксперимента:**

Гиперпараметры, которые подбирались исходя из рекомендаций в appendix раздел I оригинальной [статьи](https://arxiv.org/pdf/2108.00946):
* Ni = 1 (количество итераций алгоритма по поиску слоев для разморозки);
* Количество слоев, размороженных для обучения - в зависмости от промпта от 3 до 12, иногда 0 - все разморожено;
* lr = 0.002 # рекомендации;

Другие гиперпараметры:
* alpha = 0.5 (коэффициент при вычислении directional CLIP-loss
* latent_dim=512 (размерность латентного пространства)
* image_size = 1024 (выбрана модель stylegan2-ffhq)

Проверялись следующие промпты и сочетания параметров размороженных слоев (k-top) и итераций (steps), c выбором лучшего визуального результата (best):
1. Shrek from face
k-top: 12 - 10 - 5 - 3,
Steps: 300 - 150.
Best: 3-150

2. Anime paintig from face:
k-top: 10 - 5 - 0, 
Steps: 300.
Best: 10-300.

3. Pixar cartoon from face
k-top: 10, 
Steps: 300.
Best: 10-300.

4. Sketch from face
k-top: 10 - 0 - 8 - 5 - 3 - 12, 
Steps: 300.
Best: 10-300.

5. Zoombie from face
k-top: 12 - 3 - 5 - 8,
Steps: 300.
Вest: 5-300.

**Описание результатов**

Изучена [статья](https://arxiv.org/pdf/2108.00946).

Реализован пайплайн для:
 - подбора k-top слоев для разморозки,
 - обучения SyleGAN2-NADA модели,
 - визуализации оригинального изображения и результата после обучения,
 - сохранения чекпоинта обученной модели (в формате pt).

Опробованы пять промптов, для которых сохранены [веса модели (saved checkpoints)](https://drive.google.com/drive/folders/1a27Qx_Te2DQ95gjUhUEUW6K6VmFvcc4F?usp=sharing).


**Выводы**

Удалось:
 - Реализовать пайплайн для подбора k-top слоев для разморозки, обучения SyleGAN2-NADA модели, визуализации оригинального изображения и результата после обучения.
 - Подобрать параметры количества размороженных слоев и итераций для получения субъективно качественных изображений для каждого из пяти промптов.

Недостатки:
- Шрек был с недостаточно зеленой кожей - возможно требовалось увеличить количество итераций.
- В реализацию алгоритма выбора слоев для разморозки не была включена подсеть to_rgbs (только convs). Это могло повлиять на результат значительно.
- Закончились вычислительные ресурсы на colab и не успел попробовать запланированный промпт Dog -> Cat c рекомендованным маленьким количеством размороженных слоев (3 слоя) и большим количеством итераций (2000 итераций).
